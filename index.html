<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Yang Song's Homepage</title>
		<script type='application/ld+json'> 
		{
		  "@context": "http://www.schema.org",
		  "@type": "person",
		  "name": "Yang Song",
		  "jobTitle": "Researcher",
		  "url": "",
		  "address": {
		    "@type": "PostalAddress",
		    "addressLocality": "William & Mary",
		    "addressRegion": "Williamsburg",
		    "postalCode": "23185",
		    "addressCountry": "US"
		  },
		  "email": "ysong10@wm.edu"
		}
		 </script>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<!-- statistics -->
		<script>
		var _hmt = _hmt || [];
		(function() {
		  var hm = document.createElement("script");
		  hm.src = "https://hm.baidu.com/hm.js?c65695d70e5decd45683cf0d863f1d56";
		  var s = document.getElementsByTagName("script")[0]; 
		  s.parentNode.insertBefore(hm, s);
		})();
		</script>

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121223301-2"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-121223301-2');
		</script>

	</head>
	<body>

		<!-- Header -->
<!--			<section id="header">-->
<!--				<header>-->
<!--					<span class="image avatar"><img src="" alt="Yang Song" align="middle"></span>-->
<!--					<h1 id="logo"><a href="#">Yang Song</a></h1>-->
<!--&lt;!&ndash;					<p>Do not go gentle into that good night</p>&ndash;&gt;-->
<!--				</header>-->
<!--				<nav id="nav">-->
<!--					<ul>-->
<!--						<li><a href="#1" class="active">About</a></li>-->
<!--						<li><a href="#2">News</a></li>-->
<!--						<li><a href="#7">Research Projects</a>-->
<!--						<li><a href="#6">Publications</a></li>-->
<!--						<li><a href="#3">Work/Teaching Experience</a></li>-->
<!--						<li><a href="#4">Professional Services</a></li>-->
<!--&lt;!&ndash;						<li><a href="#5">Code Platforms</a></li>&ndash;&gt;-->
<!--&lt;!&ndash;						<li><a href="#7">Research Highlights</a></li>&ndash;&gt;-->
<!--&lt;!&ndash;						<li><a href="#8">Misc.</a></li>&ndash;&gt;-->
<!--					</ul>-->
<!--				</nav>-->
<!--				<footer>-->
<!--					<ul class="icons">-->
<!--&lt;!&ndash;						<li><a href="https://www.facebook.com/jiaxuan.you.54" class="icon fa-facebook-square"><span class="label">Facebook</span></a></li>&ndash;&gt;-->
<!--						<li><a href="https://github.com/JiaxuanYou" class="icon fa-github"><span class="label">Github</span></a></li>-->
<!--						<li><a href="https://www.linkedin.com/in/jiaxuan-you-5859b37b/" class="icon fa-linkedin-square"><span class="label">Linkedin</span></a></li>-->
<!--&lt;!&ndash;						<li><a href="https://twitter.com/youjiaxuan" class="icon fa-twitter-square"><span class="label">Twitter</span></a></li>&ndash;&gt;-->
<!--					</ul>-->
<!--				</footer>-->
<!--			</section>-->

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="1">
								<div class="container">
									<header class="major">
										<h3> Yang Song</h3> <img src="images/IMG_6109.jpg" alt="Yang Song" align="middle" height="270" width="auto">
										 <!-- (<font face=Hiragino Sans GB, Microsoft YaHei>尤佳轩</font>) -->
									</header>

									<b>Ph.D. candidate in Computer Science</b><br>
									<b>The College of William & Mary</b><br>
									<b>Email:</b> ysong10@wm.edu<br>
									[<a href="https://scholar.google.com/citations?user=KR_TUqkAAAAJ&hl=en"><font color="#6F9FD8">Google scholar</font></a>]
									[<a href="https://github.com/ysong10"><font color="#6F9FD8">Github</font></a>]
									<!-- [<a href="https://forum.aicircle.me/u/JiaxuanYou/summary"><font color="#6F9FD8">AI-Circle</font></a>] -->
									<br><br>
									<p>Hi there! I am a Ph.D. candidate in the Department of Computer Science at  <a href="https://www.wm.edu/"><font color="#6F9FD8">William & Mary</font></a>, under the supervision of Prof.
										<a href="https://ojcchar.github.io/"><font color="#6F9FD8">Oscar Chaparro</font></a>. My research interests fall in deep learning, machine learning,
										specifically multi-modal learning, natural language processing, and their applications in software engineering.
										Before coming to W&M, I got my bachelor degree in mathematics from Sichuan University. Check my CV here.
									</p>
									</p>
								</div>
							</section>


						<section id="2">
								<div class="container">
									<h3>News</h3>
									<ul>
										<li> I am looking for an intern in industry now.
										</li>
<!--										<li> [2021/04] <a href="http://web.stanford.edu/class/cs224w/"><font color="#6F9FD8">Stanford CS224W 2021</font></a> is now live updated on Youtube! As the Head TA I led the course design this year. We will update videos every Tuesday/Thursday. Enjoy the course!-->
<!--											[<a href="http://web.stanford.edu/class/cs224w/"><font color="#6F9FD8">CS224W 2021 slides</font></a>], [<a href="https://www.youtube.com/watch?v=JAB_plj2rbA&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn"><font color="#6F9FD8">CS224W 2021 Youtube playlist</font></a>] <br>-->
<!--										<li> [2020/10] I released <a href="https://github.com/snap-stanford/GraphGym"><font color="#6F9FD8">GraphGym</font></a>, an easy-to-use platform for designing and evaluating GNNs. Welcome to try it out! <br>-->
									</ul>
								</div>
							</section>


<!--						<section id="7">-->
<!--							<div class="container">-->
<!--								<h3>Highlighted Projects</h3>-->
<!--								<div class="features">-->
<!--&lt;!&ndash;									<h4>Latest papers</h4>&ndash;&gt;-->
<!--									<article>-->
<!--										<a href="images/IDGNN.png" class="image"><img src="images/IDGNN.png" alt="Yang Song" style="width:480;height:450;">[Full image]</a>-->
<!--										<div class="inner">-->
<!--											<h4>Bee: a tool for structuring and analyzing bug reports&nbsp;&nbsp; (FSE2020)</h4>-->
<!--											<p>-->
<!--												<br>-->
<!--												[<a href="https://ojcchar.github.io/files/16-fse20-bee.pdf"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/snap-stanford/GraphGym"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/idgnn"><font color="#6F9FD8">Webpage</font></a>]-->
<!--											</p>-->
<!--										</div>-->
<!--									</article>-->

<!--								</div>-->
<!--							</div>-->
<!--						</section>-->



						<section id="6">
							<div class="container">
								<h3>Publications</h3>
								<ol>

									<li>
										<b>On the Automated Mapping of Bug Descriptions to Mobile App UI Screens</b><br>
										<b>Yang Song</b>, Antu Saha, Ying Zhou, Junayed Mahmud, Kevin Moran, Oscar Chaparro<br>
										Under Review

									</li>


									<li>
										<b>BURT: A Chatbot for Interactive Bug Reporting</b><br>
										<b>Yang Song</b>, Junayed Mahmud, Nadeeshan De Silva, Ying Zhou, Oscar Chaparro, Kevin Moran, Andrian Marcus<br>
										<i> Proceedings of the 45th IEEE/ACM International Conference on Software Engineering (ICSE'23) </i> <br>
										Tool demo track, pp. 170-174, 2023 -
										[<a href="https://arxiv.org/pdf/2302.06050.pdf"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/sea-lab-wm/burt"><font color="#6F9FD8">Package</font></a>]&nbsp;[<a href="https://github.com/sea-lab-wm/burt/tree/tool-demo"><font color="#6F9FD8">Tool</font></a>]

									</li>

									<li>
										<b>Recommending Bug Assignment Approaches for Individual Bug Reports: An Empirical Investigation</b><br>
										<b>Yang Song</b>, Oscar Chaparro<br>
										arXiv:2305.18650, 2023 - [<a href="https://arxiv.org/pdf/2305.18650.pdf"><font color="#6F9FD8">PDF</font></a>]&nbsp;

									</li>


									<li>
										<b>Toward Interactive Bug Reporting for (Android App) End-Users</b><br>
										<b>Yang Song</b>, Junayed Mahmud, Ying Zhou, Oscar Chaparro, Kevin Moran, Andrian Marcus<br>
										<i>Proceedings of the 28th ACM Joint Meeting on the Foundations of Software Engineering (ESEC/FSE'22) </i> <br>
										Research track, pp.344–356, 2022 - [<a href="https://dl.acm.org/doi/pdf/10.1145/3540250.3549131"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/sea-lab-wm/burt"><font color="#6F9FD8">Package</font></a>]&nbsp;[<a href="https://github.com/sea-lab-wm/burt"><font color="#6F9FD8">Tool</font></a>]

									</li>

									<li>
										<b>Bee: a tool for structuring and analyzing bug reports</b><br>
										<b>Yang Song</b>, Oscar Chaparro<br>
										<i>Proceedings of the 28th ACM Joint Meeting on the Foundations of Software Engineering (ESEC/FSE'20) </i> <br>
										Tool demo track, pp. 1551-1555, 2020 - [<a href="https://ojcchar.github.io/files/16-fse20-bee.pdf"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/sea-lab-wm/bee-tool/tree/master/fse20-evaluation"><font color="#6F9FD8">Package</font></a>]&nbsp;[<a href="https://github.com/sea-lab-wm/bee-tool"><font color="#6F9FD8">Tool</font></a>]

									</li>





                               </ol>
							</div>
						</section>

						<section id="3">
								<div class="container">
									<h3>Work/Teaching Experience</h3>
									<ul>
										<li> <b>2020/03 - present  &nbsp &nbsp &nbsp Research Assistant, William & Mary</b>
										<li> <b>2018/09 - 2020/05  &nbsp &nbsp Teaching Assistant, William & Mary</b>
									</ul>
								</div>
							</section>


						<section id="4">
								<div class="container">
									<h3>Academic Service</h3>
									<ul>
										<li> <b>Sub-reviewer:</b> <i> ASE 2021, ICSME 2021, ICSME 2022, FSE 2023, ICSE 2023</i>
										<li> <b>Volunteer: </b> <i>FSE 2020, ICSE 2020, ICSME 2023</i>


										<!-- <b>Worshops</b>: <i>NeurIPS 2018 Workshop on Relational Representation Learning, ICLR 2019 Workshop on Representation Learning on Graphs and Manifolds, ICML 2019 Workshop on Learning and Reasoning with Graph-Structured Data, NeurIPS 2019 Workshop on Graph Representation Learning </i> -->
									</ul>
								</div>
							</section>


						<!-- Three -->


<!--							<section id="7">-->
<!--								<div class="container">-->
<!--									<h3>Research Highlights</h3>-->
<!--									<div class="features">-->
<!--										<h4>Latest papers</h4>-->
<!--												<article>-->
<!--													<a href="images/IDGNN.png" class="image"><img src="images/IDGNN.png" alt="Jiaxuan You" style="width:480;height:450;">[Full image]</a>-->
<!--													<div class="inner">-->
<!--														<h4>Identity-aware Graph Neural Networks&nbsp;&nbsp; (AAAI 2021)</h4>-->
<!--														<p>	Here we develop a class of message passing GNNs, named Identity-aware Graph Neural Networks (ID-GNNs), with greater expressive power than the 1-WL test. -->
<!--															ID-GNN offers a minimal but powerful solution to limitations of existing GNNs.-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/2101.10320"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/snap-stanford/GraphGym"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/idgnn"><font color="#6F9FD8">Webpage</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->


<!--												<article>-->
<!--													<a href="images/GraphGym.png" class="image"><img src="images/GraphGym.png" alt="Jiaxuan You" style="width:480;height:450;">[Full image]</a>-->
<!--													<div class="inner">-->
<!--														<h4>Design Space for Graph Neural Networks&nbsp;&nbsp; (NeruIPS 2020)</h4>-->
<!--														<p>	Here we define and systematically study the architectural design space for GNNs which consists of 315,000 different designs over 32 different predictive tasks. -->
<!--															We release GraphGym, a powerful platform for exploring different GNN designs and tasks.-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/2011.08843"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/snap-stanford/GraphGym"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/gnn-design"><font color="#6F9FD8">Webpage</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--										-->

<!--												<article>-->
<!--													<a href="images/grape.png" class="image"><img src="images/grape.png" alt="Jiaxuan You" style="width:480;height:450;">[Full image]</a>-->
<!--													<div class="inner">-->
<!--														<h4>Handling Missing Data with Graph Neural Networks&nbsp;&nbsp; (NeruIPS 2020)</h4>-->
<!--														<p>	Here, we propose GRAPE, a general framework for feature imputation and label prediction in the-->
<!--															presence of missing data. Our key innovation is to formulate the problem using a graph representation,-->
<!--															where observations and features are two types of nodes, and the observed feature values are attributed edges.-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/2010.16418"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/maxiaoba/GRAPE"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/grape"><font color="#6F9FD8">Webpage</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--									-->

<!--												<article>-->
<!--													<a href="images/graph_structure.png" class="image"><img src="images/graph_structure.png" alt="Jiaxuan You" style="width:480;height:450;">[Full image]</a>-->
<!--													<div class="inner">-->
<!--														<h4>Graph Structure of Neural Networks&nbsp;&nbsp; (ICML 2020)</h4>-->
<!--														<p>	Here we systematically investigate how does the graph structure of neural networks affect their predictive performance.-->
<!--															Our work opens new directions for the design of neural architectures and the understanding on neural networks in general.-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/2007.06559"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/facebookresearch/graph2nn"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://icml.cc/virtual/2020/poster/5795"><font color="#6F9FD8">Video Recording</font></a>]&nbsp;[<a href="files/Graph_Structure_of_Neural_Networks_slides.pdf"><font color="#6F9FD8">Slides</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--										<ol>-->
<!--											-->
<!--										<h4><li>Deep generative models for graphs ("Graph decoder")</h4>-->
<!--											<ul>-->
<!--												<li><b>GraphRNN</b>: one of the first deep generative models for graphs</li>-->
<!--												<article>-->
<!--													<a href="images/GraphRNN.png" class="image"><img src="images/GraphRNN.png" alt="Jiaxuan You" style="width:480;height:450;"></a>-->
<!--													<div class="inner">-->
<!--														<h4>GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Model&nbsp;&nbsp; (ICML 2018)</h4>-->
<!--														<p>	Here we-->
<!--															propose GraphRNN, a deep autoregressive model-->
<!--															that addresses the above challenges and approximates-->
<!--															any distribution of graphs with minimal-->
<!--															assumptions about their structure.-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/1802.08773"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/JiaxuanYou/graph-generation"><font color="#6F9FD8">Code</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->
<!--												-->
<!--												<li><b>GCPN</b>: generate graph to satisfy user-provided goals, applied to molecule generation</li>-->

<!--												<article>-->
<!--													<a href="images/GCPN.jpg" class="image"><img src="images/GCPN.jpg" alt="Jiaxuan You" style="width:480;height:400;">[Full image]</a>-->
<!--													<div class="inner">-->
<!--														<h4>GCPN: Reinforcement Learning for Goal-Directed Molecular Graph Generation&nbsp;&nbsp; (NeruIPS 2018)</h4>-->
<!--														<p> Here we propose Graph Convolutional Policy-->
<!--															Network (GCPN), a general graph convolutional network based model for goal-directed-->
<!--															graph generation through reinforcement learning.-->
<!--															<br>[<a href="https://arxiv.org/abs/1806.02473"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/bowenliu16/rl_graph_generation"><font color="#6F9FD8">Code</font></a>]&nbsp;-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--												<li><b>G2SAT</b>: highly scalable graph generator (over 25K nodes), applied to SAT formula generation</li>-->


<!--												<article>-->
<!--													<a href="images/G2SAT.png" class="image"><img src="images/G2SAT.png" alt="Jiaxuan You" style="width:480;height:400;">[Full image]</a>-->
<!--													<div class="inner">-->
<!--														<h4>G2SAT: Learning to Generate SAT Formulas <br> (NeurIPS 2019)</h4>-->
<!--														<p> -->
<!--															Here we present G2SAT, the first deep generative framework that learns to generate SAT formulas from a given set of input formulas. -->
<!--														    <br>-->
<!--														    [<a href="https://arxiv.org/abs/1910.13445"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/JiaxuanYou/G2SAT"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/g2sat"><font color="#6F9FD8">Webpage</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--											</ul>-->
<!--											</li>-->

<!--										<h4><li>Advanced representation learning models for graphs ("Graph encoder")</h4>-->
<!--									-->
<!--												<article>-->
<!--													<a href="images/Diffpool.png" class="image"><img src="images/Diffpool.png" alt="Jiaxuan You" style="width:480;height:400;"></a>-->
<!--													<div class="inner">-->
<!--														<h4>DiffPool: Differentiable Pooling layer for Graph Networks&nbsp;&nbsp; (NeurIPS 2018)</h4>-->
<!--														<p>-->
<!--															Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion.-->
<!--														<br>-->
<!--														[<a href="https://arxiv.org/abs/1806.08804"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/RexYing/diffpool"><font color="#6F9FD8">Code</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->


<!--												<article>-->
<!--													<a href="images/PGNN.png" class="image"><img src="images/PGNN.png" alt="Jiaxuan You" style="width:480;height:400;"></a>-->
<!--													<div class="inner">-->
<!--														<h4>P-GNN: Position-aware Graph Neural Networks&nbsp;&nbsp; (ICML 2019)</h4>-->
<!--														<p> -->
<!--															Here we propose Position-aware Graph Neural Networks (PGNNs), a new class of GNNs for computing-->
<!--															position-aware node embeddings which existing GNNs cannot represent.-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/1906.04817"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/JiaxuanYou/P-GNN"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/pgnn"><font color="#6F9FD8">Webpage</font></a>]&nbsp;[<a href="https://slideslive.com/38917935"><font color="#6F9FD8">Video Recording</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--	-->

<!--										<h4><li>Applications that leverage graph structure</h4>-->

<!--												<article>-->
<!--													<a href="images/HierTCN.png" class="image"><img src="images/HierTCN.png" alt="Jiaxuan You" style="width:480;height:400;"></a>-->
<!--													<div class="inner">-->
<!--														<h4>HierTCN: Hierarchical Temporal Convolutional Networks for Dynamic Recommender Systems&nbsp;&nbsp; (WWW 2019)</h4>-->
<!--														<p> -->
<!--															Here we propose Hierarchical Temporal Convolutional Networks (HierTCN), a hierarchical deep learning architecture that makes dynamic recommendations based on users' sequential multi-session interactions with items.-->
<!--														<br>[<a href="https://arxiv.org/abs/1904.04381"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/JiaxuanYou/HierTCN"><font color="#6F9FD8">Code</font></a>]-->
<!--															&lt;!&ndash; <br>[<a href="https://arxiv.org/abs/1806.02473"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/bowenliu16/rl_graph_generation"><font color="#6F9FD8">Code</font></a>]&nbsp; &ndash;&gt;-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->

<!--												<article>-->
<!--													<a href="images/GNNExplainer.png" class="image"><img src="images/GNNExplainer.png" alt="Jiaxuan You" style="width:480;height:400;"></a>-->
<!--													<div class="inner">-->
<!--														<h4>GNNExplainer: A Tool for Post-hoc Explanation of Graph Neural Networks&nbsp;&nbsp; (NeurIPS 2019)</h4>-->
<!--														<p> -->
<!--															Here we propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based-->
<!--															machine learning task.-->
<!--		&lt;!&ndash; 													GNNs combine node feature information with the graph structure by-->
<!--															recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models-->
<!--															and explaining predictions made by GNNs remains unsolved. Here we propose-->
<!--															GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based-->
<!--															machine learning task. Given an instance, GNNExplainer identifies a compact-->
<!--															subgraph structure and a small subset of node features that have a crucial role in-->
<!--															GNN’s prediction. Further, GNNExplainer can generate consistent and concise-->
<!--															explanations for an entire class of instances. Experiments on synthetic and-->
<!--															real-world graphs show that our approach can identify important graph structures-->
<!--															as well as node features, and outperforms baselines by 17.1% on average. GNNExplainer provides a variety of benefits, from the ability to visualize semantically-->
<!--															relevant structures to interpretability, to giving insights into errors of faulty GNNs.  &ndash;&gt;-->
<!--															<br>-->
<!--															[<a href="https://arxiv.org/abs/1903.03894"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/RexYing/gnn-model-explainer"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="https://snap.stanford.edu/gnnexplainer"><font color="#6F9FD8">Webpage</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->


<!--												<article>-->
<!--													<a href="images/HAG.png" class="image"><img src="images/HAG.png" alt="Jiaxuan You" style="width:480;height:400;"></a>-->
<!--													<div class="inner">-->
<!--														<h4>HAG: Redundancy-Free Computation Graphs for Graph Neural Networks​&nbsp;&nbsp; (KDD 2020)</h4>-->
<!--														<p> -->
<!--															Here we propose Hierarchically Aggregated computation Graphs (HAGs), a new GNN representation technique that explicitly avoids redundancy by managing intermediate aggre- gation results hierarchically and eliminates repeated computations and unnecessary data transfers in GNN training and inference.<br>-->
<!--															[<a href="https://arxiv.org/abs/1906.03707"><font color="#6F9FD8">PDF</font></a>]-->
<!--														</p>-->
<!--													</div>-->
<!--												</article>-->




<!--										<h4><li>Interdisciplinary research</h4>-->

<!--											<article>-->
<!--											<a href="images/crop.gif" class="image"><img src="images/crop.gif" alt="Jiaxuan You" style="width:480;height:400;"></a>-->
<!--											<div class="inner">-->
<!--												<h4>Crop Yield Prediction: Machine Learning over Satellite Images &nbsp;&nbsp; (AAAI 2017)</h4>-->
<!--												<p>Crop yield prediction is central in ensuring the food security. We introduce the first deep learning based method to predict crop yield purely based on publicly available remote sensing data.-->
<!--												<br>[<a href="files/Jiaxuan_AAAI17.pdf"><font color="#6F9FD8">PDF</font></a>]&nbsp;[<a href="https://github.com/JiaxuanYou/crop_yield_prediction"><font color="#6F9FD8">Code</font></a>]&nbsp;[<a href="http://sustain.stanford.edu/crop-yield-analysis"><font color="#6F9FD8">Project Webpage</font></a>]-->
<!--												</p>-->
<!--												</div>-->
<!--											</article>-->

<!--											<article>-->
<!--												<a href="images/metro_map.png" class="image"><img src="images/metro_map.png" alt="Jiaxuan You" style="width:480;height:300;"></a>-->
<!--												<div class="inner">-->
<!--													<h4>An Effective Simulation Model for Multi-line Metro Systems &nbsp;&nbsp; (ITSC 2016)</h4>-->
<!--													<p>This paper presents an effective simulation model for-->
<!--													multi-line metro systems based on the OD (origin-destination)-->
<!--													data and the network connection data.-->
<!--													<br>[<a href="files/ITSC2016.pdf"><font color="#6F9FD8">PDF</font></a>]&nbsp;-->
<!--													</p>-->
<!--												</div>-->
<!--											</article>-->
<!--											-->
<!--										-->
<!--										</ol>-->

<!--										-->

<!--										-->

<!--									</div>-->
<!--								</div>-->
<!--							</section>-->



<!--							<section id="6">-->
<!--								<div class="container">-->
<!--									<h3>Skills</h3>-->
<!--									<ul>-->
<!--										<li><h4>Course work</h4>-->
<!--										<b>AI</b>: Machine learning, Pattern Recognition, Database Systems, Data structures<br>-->
<!--										<b>Mathematics</b>: Probability and Statistics, Calculus, Linear Algebra, Complex Analysis, Numerical Analysis</li>-->
<!--										<li><h4>Programming</h4>-->
<!--										Python, C/C++, C#, MATLAB, Octave, LaTeX, TensorFlow</li>-->
<!--										<li><h4>English</h4>-->
<!--										<b>GRE</b>: Verbal-161, Quantitative-167 &nbsp; <b>TOEFL iBT</b>: 109</li>-->
<!--									</ul>-->
<!--								</div>-->
<!--							</section>-->


					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; HTML5 UP 2016</li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollzer.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
